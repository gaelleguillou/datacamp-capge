{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Scrapy: Getting reviews from Booking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.selector import Selector\n",
    "import sys\n",
    "from scrapy.http import Request\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Some class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define here the models for your scraped items\n",
    "#\n",
    "# See documentation in:\n",
    "# https://doc.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "class HotelreviewsItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    rating = scrapy.Field()\n",
    "    review_title = scrapy.Field()\n",
    "    review_neg = scrapy.Field()\n",
    "    review_pos = scrapy.Field()\n",
    "    review_language = scrapy.Field()\n",
    "    reviewer_name = scrapy.Field()\n",
    "    reviewer_nationality = scrapy.Field()\n",
    "    reviewer_nb_comments = scrapy.Field()\n",
    "    published_date = scrapy.Field()\n",
    "    hotel_name = scrapy.Field()\n",
    "    trip_date = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the JSon pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSon pipeline, you can rename the \"trust.jl\" to the name of your choice\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('booking.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spider\n",
    "\n",
    "Now you know how to get data from one page, we want to automate the spider so it will crawl through all pages of reviews, ending with a full spider able to scrape every reviews of the selected parc. You will modify here the parse function since this is where you tell the spider to get the links and to follow them. <br>\n",
    "<b>To Do</b>: Complete the following code, to scrape all the reviews of one parc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySpider(CrawlSpider):\n",
    "    name = 'BasicSpider'\n",
    "    domain_url = \"https://www.booking.com\"\n",
    "\n",
    "    start_urls = [\n",
    "        \"https://www.booking.com/reviews/nl/hotel/center-parcs-de-eemhof.fr.html\",\n",
    "        \"https://www.booking.com/reviews/nl/hotel/center-parcs-de-eemhof.en.html\"\n",
    "    ]\n",
    "    \n",
    "        #Custom settings to modify settings usually found in the settings.py file \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'booking_eemhof.json'                        # Used for pipeline 2\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        n_comments = int(response.xpath('//p[@class=\"page_showing\"]/text()').extract_first().strip()[-2:])\n",
    "        \n",
    "        scores = list(map(lambda x: float(x.strip().replace(',','.')), list(response.xpath('//span[@class=\"review-score-badge\"]/text()').extract())))\n",
    "        \n",
    "        descriptions = list(response.xpath('//div[@class=\"review_item_review_content\"]'))\n",
    "        \n",
    "        reviewer_names = response.xpath('//p[@class=\"reviewer_name\"]/span/text()').extract()\n",
    "        \n",
    "        published_dates = response.xpath('//meta[@itemprop=\"datePublished\"]/@content').extract()\n",
    "        \n",
    "        n_comments_per_reviewers = response.xpath('//div[@class=\"review_item_user_review_count\"]/text()').extract()\n",
    "        \n",
    "        reviewer_nationalities = response.xpath('//span[@itemprop=\"nationality\"]/span/text()').extract()\n",
    "        \n",
    "        hotel_name = response.xpath('//h1[@class=\"item hotel_name\"]/a[@class=\"standalone_header_hotel_link\"]/text()').extract_first()\n",
    "        \n",
    "        review_titles = response.xpath('//div[@class=\"review_item_header_content\\n\"]/span/text()').extract()\n",
    "        \n",
    "        review_language = response.xpath('//div[@class=\"review_sort_container \"][1]/select[@id=\"language\"]/option[@selected]/text()').extract_first()\n",
    "        \n",
    "        for i in range(n_comments):\n",
    "            \n",
    "            item = HotelreviewsItem()\n",
    "\n",
    "            item['rating'] = scores[i]\n",
    "            \n",
    "            item['review_title'] = review_titles[i]\n",
    "            \n",
    "            item[\"review_neg\"] = Selector(text=descriptions[i].extract()).xpath('//p[@class=\"review_neg \"]//span[@itemprop=\"reviewBody\"]//text()').extract_first()\n",
    "            \n",
    "            item[\"review_pos\"] = Selector(text=descriptions[i].extract()).xpath('//p[@class=\"review_pos \"]//span[@itemprop=\"reviewBody\"]//text()').extract_first()\n",
    "            \n",
    "            item['reviewer_name'] = reviewer_names[i]\n",
    "            \n",
    "            item['published_date'] = published_dates[i]\n",
    "            \n",
    "            item['reviewer_nb_comments'] = int(re.findall(r'\\d+', n_comments_per_reviewers[i].strip())[0])\n",
    "            \n",
    "            item['reviewer_nationality'] = reviewer_nationalities[i].strip()\n",
    "            \n",
    "            item['hotel_name'] = hotel_name\n",
    "            \n",
    "            item['review_language'] = review_language\n",
    "            \n",
    "            item['trip_date'] = re.findall('\\\\S+\\\\s+\\\\S+$', \n",
    "                                           Selector(text=descriptions[2].extract()).xpath('//p[@class=\"review_staydate \"]/text()').extract_first().strip()\n",
    "                                          )[0] or None\n",
    "\n",
    "            yield item\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-24 20:39:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)\n",
      "2019-01-24 20:39:05 [scrapy.utils.log] INFO: Versions: lxml 4.3.0.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) - [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Darwin-18.2.0-x86_64-i386-64bit\n",
      "2019-01-24 20:39:05 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'booking_eemhof.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'\n",
    "})\n",
    "\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importing and reading data scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjson = pd.read_json('booking_eemhof.json')\n",
    "\n",
    "# Removing \\r characters causing issues in csv\n",
    "for col in dfjson.columns:\n",
    "    if dfjson.dtypes[col] == 'object':\n",
    "        dfjson[col] = dfjson[col].apply(lambda x: x.replace('\\r', '') if x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjson.to_csv('booking_eemhof.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
